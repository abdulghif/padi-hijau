{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\distributed\\config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "\n",
    "# library untuk eksplorasi data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# library untuk membagi data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# library untuk evaluasi hasil prediksi\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# library untuk bebrapa model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# library untuk tunning parameter\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# library untuk menggabungkan beberapa algoritme\n",
    "from imblearn.pipeline import Pipeline\n",
    "# library untuk menyeimbangkan data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# import category_encoders as ce\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "df_train_prep1 = df_train.copy()\n",
    "df_test_prep1 = df_test.copy()\n",
    "\n",
    "def Pipelining(df_train_prep1,df_test_prep1):\n",
    "    ################################ Preprocess and Data Cleaning ############################\n",
    "\n",
    "    ################################ Preprocess and Data Cleaning ############################\n",
    "\n",
    "    df_train_prep1['Achievement_above_100%_during3quartal'].fillna(0, inplace = True)\n",
    "\n",
    "    df_train_prep1['GPA'] = np.where(df_train_prep1['GPA']>100,df_train_prep1['GPA']/100,df_train_prep1['GPA'])\n",
    "    df_train_prep1['GPA'] = np.where(df_train_prep1['Education_level'].isin(['level_0','level_1']),0,df_train_prep1['GPA'])\n",
    "    df_train_prep1['GPA'] = np.where((df_train_prep1['GPA']==0)&(df_train_prep1['Education_level'] == 'level_4'),3,df_train_prep1['GPA'])\n",
    "\n",
    "    df_test_prep1['GPA'] = np.where(df_test['GPA']>100,df_test['GPA']/100,df_test['GPA'])\n",
    "    df_test_prep1['GPA'] = np.where(df_test_prep1['Education_level'].isin(['level_0','level_1']),0,df_test_prep1['GPA'])\n",
    "    df_test_prep1['GPA'] = np.where((df_test_prep1['GPA']==0)&(df_test_prep1['Education_level'] == 'level_4'),3,df_test_prep1['GPA'])\n",
    "\n",
    "    ################################ Feature Engineering ############################\n",
    "\n",
    "    def age_2(x):\n",
    "        if x <= 35:\n",
    "            return 'ambis'\n",
    "        elif x > 35:\n",
    "            return 'non-ambis'\n",
    "\n",
    "    def age_3(x):\n",
    "        if x <= 25:\n",
    "            return 1\n",
    "        elif x <= 35:\n",
    "            return 2\n",
    "        elif x <= 45:\n",
    "            return 3\n",
    "        elif x <= 55:\n",
    "            return 4\n",
    "        elif x <= 65:\n",
    "            return 5\n",
    "\n",
    "    def year_graduated_2(x):\n",
    "        if x >= 2015:\n",
    "            return 'young'\n",
    "        elif x < 2015:\n",
    "            return 'old'\n",
    "\n",
    "\n",
    "    # TOTAL LEAVE \n",
    "\n",
    "    df_train_prep1['total leave'] = df_train_prep1['annual leave'] + df_train_prep1['sick_leaves']\n",
    "    df_test_prep1['total leave'] = df_test_prep1['annual leave'] + df_test_prep1['sick_leaves']\n",
    "\n",
    "    # AGE\n",
    "\n",
    "    df_train_prep1['age2'] = 2020 - df_train_prep1['age']\n",
    "    df_train_prep1['age2'] = df_train_prep1['age2'].apply(age_2)\n",
    "\n",
    "    df_test_prep1['age2'] = 2020 - df_test_prep1['age']\n",
    "    df_test_prep1['age2'] = df_test_prep1['age2'].apply(age_2)\n",
    "\n",
    "    df_train_prep1['age3'] = 2020 - df_train_prep1['age']\n",
    "    df_train_prep1['age3'] = df_train_prep1['age3'].apply(age_3)\n",
    "\n",
    "    df_test_prep1['age3'] = 2020 - df_test_prep1['age']\n",
    "    df_test_prep1['age3'] = df_test_prep1['age3'].apply(age_3)\n",
    "\n",
    "    # YEAR GRADUATED\n",
    "\n",
    "    df_train_prep1['year_graduated2'] = df_train_prep1['year_graduated'].apply(year_graduated_2)\n",
    "    df_test_prep1['year_graduated2'] = df_test_prep1['year_graduated'].apply(year_graduated_2)\n",
    "\n",
    "    # TOTAL ROTATION\n",
    "\n",
    "    df_train_prep1['total_rotation'] = df_train_prep1['branch_rotation'] + df_train_prep1['job_rotation'] + df_train_prep1['assign_of_otherposition']\n",
    "    df_test_prep1['total_rotation'] = df_test_prep1['branch_rotation'] + df_test_prep1['job_rotation'] + df_test_prep1['assign_of_otherposition']\n",
    "\n",
    "    # IPK O\n",
    "\n",
    "    df_train_prep1['in study'] = np.where((df_train_prep1['GPA'] == 0)&(df_train_prep1['Education_level'].isin(['level_3','level_4','level_5'])),'study','finish')\n",
    "    df_test_prep1['in study'] = np.where((df_test_prep1['GPA'] == 0)&(df_test_prep1['Education_level'].isin(['level_3','level_4','level_5'])),'study','finish')\n",
    "\n",
    "    # LEVEL UP PERSON\n",
    "\n",
    "    df_train_prep1['person level up'] = np.where(df_train_prep1['job_duration_in_current_job_level']>df_train_prep1['job_duration_in_current_person_level'],'up','stay')\n",
    "    df_test_prep1['person level up'] = np.where(df_test_prep1['job_duration_in_current_job_level']>df_test_prep1['job_duration_in_current_person_level'],'up','stay')\n",
    "\n",
    "    # NEW VAR FOR ONE HOT\n",
    "\n",
    "    df_train_prep1['job_level_oh'] = df_train_prep1['job_level'] \n",
    "    df_train_prep1['person_level_oh'] = df_train_prep1['person_level']\n",
    "\n",
    "    df_test_prep1['job_level_oh'] = df_test_prep1['job_level'] \n",
    "    df_test_prep1['person_level_oh'] = df_test_prep1['person_level']\n",
    "    \n",
    "    # leave or sick\n",
    "    \n",
    "    df_train_prep1['sick_vs_leaves'] = np.where(df_train_prep1['annual leave']>df_train_prep1['sick_leaves'],'leave',np.where(df_train_prep1['annual leave']==df_train_prep1['sick_leaves'],'sama','sick'))\n",
    "    df_test_prep1['sick_vs_leaves'] = np.where(df_test_prep1['annual leave']>df_test_prep1['sick_leaves'],'leave',np.where(df_test_prep1['annual leave']==df_test_prep1['sick_leaves'],'sama','sick'))\n",
    "\n",
    "    # age when graduated\n",
    "    \n",
    "    df_train_prep1['age when graduated'] = df_train_prep1['year_graduated'] - df_train_prep1['age']\n",
    "    df_train_prep1['age when graduated2'] = np.where(df_train_prep1['Education_level'].isin(['level_4','level_3']),df_train_prep1['Education_level'].isin(['level_4','level_3'])*df_train_prep1['age when graduated'],0)\n",
    "\n",
    "    df_test_prep1['age when graduated'] = df_test_prep1['year_graduated'] - df_test_prep1['age']\n",
    "    df_test_prep1['age when graduated2'] = np.where(df_test_prep1['Education_level'].isin(['level_4','level_3']),df_test_prep1['Education_level'].isin(['level_4','level_3'])*df_test_prep1['age when graduated'],0)\n",
    "    \n",
    "    # age per dependencies\n",
    "\n",
    "    df_train_prep1['age per dependencies'] = (2020-df_train_prep1['age'])/(df_train_prep1['number_of_dependences']+1)\n",
    "    df_test_prep1['age per dependencies'] = (2020-df_test_prep1['age'])/(df_test_prep1['number_of_dependences']+1)\n",
    "\n",
    "    # age maried male\n",
    "\n",
    "    df_train_prep1['age married male'] = (2020-df_train_prep1['age'])*(df_train_prep1['marital_status_maried(Y/N)'] == 'Y')*(df_train_prep1['gender']==1)\n",
    "    df_test_prep1['age married male'] = (2020-df_test_prep1['age'])*(df_test_prep1['marital_status_maried(Y/N)'] == 'Y')*(df_test_prep1['gender']==1)\n",
    "\n",
    "    df_train_prep1['papa muda'] = np.where((df_train_prep1['age married male']>=24.9)&(df_train_prep1['age married male']<=32),df_train_prep1['age married male'],0)\n",
    "    df_test_prep1['papa muda'] = np.where((df_test_prep1['age married male']>=24.9)&(df_test_prep1['age married male']<=32),df_test_prep1['age married male'],0)\n",
    "    \n",
    "    # age per dependencies papa muda\n",
    "    \n",
    "    df_train_prep1['papa muda per tanggungan'] = df_train_prep1['papa muda']/(df_train_prep1['number_of_dependences']+1)\n",
    "    df_test_prep1['papa muda per tanggungan'] = df_test_prep1['papa muda']/(df_test_prep1['number_of_dependences']+1)\n",
    "    \n",
    "    ############################### Feature Engineering Scikit ############################\n",
    "\n",
    "    # MODELING\n",
    "\n",
    "    new_var_one_hot = ['age2','age3','year_graduated2','in study','person level up','sick_vs_leaves']\n",
    "\n",
    "    one_hot_var = [\n",
    "        'job_level_oh', \n",
    "        'person_level_oh', \n",
    "        'Employee_type', \n",
    "        'Education_level',\n",
    "    #     'Employee_status',   \n",
    "        'gender', \n",
    "        'marital_status_maried(Y/N)'] + new_var_one_hot\n",
    "\n",
    "    ordinal_val = [\n",
    "        'job_level',\n",
    "        'person_level',\n",
    "        'Education_level'\n",
    "    #     'achievement_target_1', \n",
    "    #     'achievement_target_2'\n",
    "    ]\n",
    "\n",
    "    new_var_num = ['year_graduated','total leave','total_rotation',\n",
    "                   'age when graduated','age when graduated2','papa muda']\n",
    "#                    'papa muda per tanggungan']\n",
    "\n",
    "    numeric_var = [\n",
    "        'job_duration_in_current_job_level',   \n",
    "        'job_duration_in_current_person_level',\n",
    "        'job_duration_in_current_branch', \n",
    "        'age', \n",
    "        'number_of_dependences',\n",
    "        'GPA',   \n",
    "        'branch_rotation', \n",
    "        'job_rotation', \n",
    "        'assign_of_otherposition',   \n",
    "        'annual leave', \n",
    "        'sick_leaves',\n",
    "        'Last_achievement_%', \n",
    "        'Achievement_above_100%_during3quartal'] + new_var_num\n",
    "\n",
    "    # ordinal_mapping = [\n",
    "    #     {'col':'job_level',\n",
    "    #     'mapping':{None:0,'JG04':1,'JG05':2,'JG03':3,'JG06':4}},\n",
    "    #     {'col':'person_level',\n",
    "    #     'mapping':{None:0,'PG01':1,'PG02':2,'PG03':3,'PG04':4, 'PG05':5, 'PG06':6, 'PG07':7, 'PG08':8}},\n",
    "    #     {'col':'Education_level',\n",
    "    #     'mapping':{None:0,'level_0':1,'level_1':2,'level_2':3, 'level_3':4, 'level_4':5, 'level_5':6}}    \n",
    "    #     ]\n",
    "\n",
    "    # ordinal_encoder = ce.OrdinalEncoder(cols = ['job_level','person_level','Education_level'],mapping = ordinal_mapping)\n",
    "\n",
    "    one_hot_encoder_pipeline = Pipeline([\n",
    "                                        ('one hot encoder',OneHotEncoder(handle_unknown = 'ignore'))\n",
    "    ])\n",
    "\n",
    "    # numerical_pipeline = SimpleImputer(strategy = 'constant',fill_value = 0)\n",
    "\n",
    "    numerical_pipeline = Pipeline([\n",
    "                                    ('imputer',SimpleImputer(strategy = 'constant',fill_value = 0)),\n",
    "                                    ('bin',KBinsDiscretizer(encode = 'onehot',strategy = 'kmeans',n_bins=5))\n",
    "    ])\n",
    "\n",
    "    transformer = ColumnTransformer([\n",
    "        ('one hot encoder',one_hot_encoder_pipeline,one_hot_var),\n",
    "    #     ('ordinal encoder',ordinal_encoder,ordinal_val),\n",
    "        ('numerical_pipeline',numerical_pipeline,numeric_var)\n",
    "    ])\n",
    "\n",
    "    ################################ Daata Splitting ############################\n",
    "\n",
    "    var_x = numeric_var + one_hot_var #+ ordinal_val\n",
    "\n",
    "    # data to return\n",
    "    X = df_train_prep1[var_x]\n",
    "    X_sub = df_test_prep1[var_x]\n",
    "    y = df_train_prep1['Best Performance']\n",
    "\n",
    "\n",
    "    ################################ Sklearn Prepreocess Fitting ############################\n",
    "\n",
    "    # feature names\n",
    "    transformer.fit(X) # fitting only for feature namse\n",
    "    one_hot_result = list(transformer.transformers_[0][1]['one hot encoder'].get_feature_names())\n",
    "    features = one_hot_result + numeric_var\n",
    "    \n",
    "    return transformer, features, X, y, X_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:189: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n",
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:202: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 12 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n"
     ]
    }
   ],
   "source": [
    "transformer, features, X, y, X_sub = Pipelining(df_train_prep1,df_test_prep1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X,y, stratify = y, test_size = 2000, random_state = 7062021)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval,y_trainval, stratify = y_trainval, test_size = 2000, random_state = 7062021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver = 'newton-cg')\n",
    "select = SelectFromModel(model, threshold=\"median\")\n",
    "\n",
    "estimator = Pipeline([\n",
    "                      ('preprocess',transformer),\n",
    "#                       ('select',select),\n",
    "                      ('clf',model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:189: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocess',\n",
       "                 ColumnTransformer(transformers=[('one hot encoder',\n",
       "                                                  Pipeline(steps=[('one hot '\n",
       "                                                                   'encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['job_level_oh',\n",
       "                                                   'person_level_oh',\n",
       "                                                   'Employee_type',\n",
       "                                                   'Education_level', 'gender',\n",
       "                                                   'marital_status_maried(Y/N)',\n",
       "                                                   'age2', 'age3',\n",
       "                                                   'year_graduated2',\n",
       "                                                   'in study',\n",
       "                                                   'person level up',\n",
       "                                                   'sick_vs_leaves']),\n",
       "                                                 ('numerical...\n",
       "                                                   'job_duration_in_current_branch',\n",
       "                                                   'age',\n",
       "                                                   'number_of_dependences',\n",
       "                                                   'GPA', 'branch_rotation',\n",
       "                                                   'job_rotation',\n",
       "                                                   'assign_of_otherposition',\n",
       "                                                   'annual leave',\n",
       "                                                   'sick_leaves',\n",
       "                                                   'Last_achievement_%',\n",
       "                                                   'Achievement_above_100%_during3quartal',\n",
       "                                                   'year_graduated',\n",
       "                                                   'total leave',\n",
       "                                                   'total_rotation',\n",
       "                                                   'age when graduated',\n",
       "                                                   'age when graduated2',\n",
       "                                                   'papa muda'])])),\n",
       "                ('clf', LogisticRegression(solver='newton-cg'))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc 0.5953038894338509 \n",
      "\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.45      0.59      1706\n",
      "           1       0.17      0.66      0.27       294\n",
      "\n",
      "    accuracy                           0.48      2000\n",
      "   macro avg       0.53      0.55      0.43      2000\n",
      "weighted avg       0.78      0.48      0.55      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prob_test = estimator.predict_proba(X_test)[:,1]\n",
    "y_pred_test = np.where(y_prob_test > 0.13, 1, 0)\n",
    "\n",
    "print('auc',roc_auc_score(y_test,y_prob_test),'\\n')\n",
    "print('classification report \\n', classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc 0.6203313748897887 \n",
      "\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.46      0.61      6103\n",
      "           1       0.18      0.71      0.29      1050\n",
      "\n",
      "    accuracy                           0.49      7153\n",
      "   macro avg       0.54      0.58      0.45      7153\n",
      "weighted avg       0.80      0.49      0.56      7153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prob_test = estimator.predict_proba(X_train)[:,1]\n",
    "y_pred_test = np.where(y_prob_test > 0.13, 1, 0)\n",
    "\n",
    "print('auc',roc_auc_score(y_train,y_prob_test),'\\n')\n",
    "print('classification report \\n', classification_report(y_train,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:189: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n",
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:202: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 12 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(X,y)\n",
    "y_pred_sub = estimator.predict_proba(X_sub)[:,1]\n",
    "df_test['Best Performance'] = y_pred_sub\n",
    "df_submission = df_test[['Best Performance']]\n",
    "df_submission.reset_index().to_csv('submission.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
