{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\distributed\\config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "\n",
    "# library untuk eksplorasi data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# library untuk membagi data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# library untuk evaluasi hasil prediksi\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# library untuk bebrapa model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# library untuk tunning parameter\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# library untuk menggabungkan beberapa algoritme\n",
    "from imblearn.pipeline import Pipeline\n",
    "# library untuk menyeimbangkan data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# import category_encoders as ce\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_prep.csv')\n",
    "df_test = pd.read_csv('test_prep.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepaparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_prep1 = df_train.copy()\n",
    "df_test_prep1 = df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FE SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_var_one_hot = ['age2','age3','year_graduated2','in study','person level up','sick_vs_leaves']\n",
    "\n",
    "one_hot_var = [\n",
    "    'job_level_oh', \n",
    "    'person_level_oh', \n",
    "    'Employee_type', \n",
    "    'Education_level',\n",
    "#     'Employee_status',   \n",
    "    'gender', \n",
    "    'marital_status_maried(Y/N)'] + new_var_one_hot\n",
    "\n",
    "ordinal_val = [\n",
    "    'job_level',\n",
    "    'person_level',\n",
    "    'Education_level'\n",
    "#     'achievement_target_1', \n",
    "#     'achievement_target_2'\n",
    "]\n",
    "\n",
    "new_var_num = ['year_graduated','total leave','total_rotation',\n",
    "               'age when graduated','age when graduated2','papa muda',\n",
    "               'papa muda per tanggungan','age per dependencies']\n",
    "\n",
    "numeric_var = [\n",
    "    'job_duration_in_current_job_level',   \n",
    "    'job_duration_in_current_person_level',\n",
    "    'job_duration_in_current_branch', \n",
    "    'age', \n",
    "    'number_of_dependences',\n",
    "    'GPA',   \n",
    "    'branch_rotation', \n",
    "    'job_rotation', \n",
    "    'assign_of_otherposition',   \n",
    "    'annual leave', \n",
    "    'sick_leaves',\n",
    "    'Last_achievement_%', \n",
    "    'Achievement_above_100%_during3quartal'] + new_var_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal_mapping = [\n",
    "#     {'col':'job_level',\n",
    "#     'mapping':{None:0,'JG04':1,'JG05':2,'JG03':3,'JG06':4}},\n",
    "#     {'col':'person_level',\n",
    "#     'mapping':{None:0,'PG01':1,'PG02':2,'PG03':3,'PG04':4, 'PG05':5, 'PG06':6, 'PG07':7, 'PG08':8}},\n",
    "#     {'col':'Education_level',\n",
    "#     'mapping':{None:0,'level_0':1,'level_1':2,'level_2':3, 'level_3':4, 'level_4':5, 'level_5':6}}    \n",
    "#     ]\n",
    "\n",
    "# ordinal_encoder = ce.OrdinalEncoder(cols = ['job_level','person_level','Education_level'],mapping = ordinal_mapping)\n",
    "\n",
    "one_hot_encoder_pipeline = Pipeline([\n",
    "                                    ('one hot encoder',OneHotEncoder(handle_unknown = 'ignore'))\n",
    "])\n",
    "\n",
    "# numerical_pipeline = SimpleImputer(strategy = 'constant',fill_value = 0)\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "                                ('imputer',SimpleImputer(strategy = 'constant',fill_value = 0))\n",
    "#                                 ('bin',KBinsDiscretizer(encode = 'onehot',strategy = 'kmeans',n_bins=5))\n",
    "])\n",
    "\n",
    "transformer = ColumnTransformer([\n",
    "    ('one hot encoder',one_hot_encoder_pipeline,one_hot_var),\n",
    "#     ('ordinal encoder',ordinal_encoder,ordinal_val),\n",
    "    ('numerical_pipeline',numerical_pipeline,numeric_var)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_x = numeric_var + one_hot_var #+ ordinal_val\n",
    "\n",
    "X = df_train_prep1[var_x]\n",
    "X_sub = df_test_prep1[var_x]\n",
    "y = df_train_prep1['Best Performance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 1995\n",
    "seed = 70621\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X,y, stratify = y, test_size = 1500, random_state = seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval,y_trainval, stratify = y_trainval, test_size = 1500, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Model (Benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = 0.2\n",
    "\n",
    "model = XGBClassifier(\n",
    "    learning_rate = rates,\n",
    "    n_estimators = 100,\n",
    "    max_depth = 5,\n",
    "    min_child_weight = 6,\n",
    "    gamma= 30,\n",
    "    subsample = 0.7,\n",
    "    colsample_bynode = 0.4,\n",
    "    reg_alpha= 0.005,\n",
    "    objective= 'binary:logistic',\n",
    "    n_jobs = -1,\n",
    "    random_state = 20)\n",
    "\n",
    "\n",
    "# model = CalibratedClassifierCV(model)\n",
    "\n",
    "estimator = Pipeline([\n",
    "                      ('preprocess',transformer),\n",
    "                      ('clf',model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocess',\n",
       "                 ColumnTransformer(transformers=[('one hot encoder',\n",
       "                                                  Pipeline(steps=[('one hot '\n",
       "                                                                   'encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['job_level_oh',\n",
       "                                                   'person_level_oh',\n",
       "                                                   'Employee_type',\n",
       "                                                   'Education_level', 'gender',\n",
       "                                                   'marital_status_maried(Y/N)',\n",
       "                                                   'age2', 'age3',\n",
       "                                                   'year_graduated2',\n",
       "                                                   'in study',\n",
       "                                                   'person level up',\n",
       "                                                   'sick_vs_leaves']),\n",
       "                                                 ('numerical...\n",
       "                               colsample_bytree=1, gamma=30, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='', learning_rate=0.2,\n",
       "                               max_delta_step=0, max_depth=5,\n",
       "                               min_child_weight=6, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=-1, num_parallel_tree=1, random_state=20,\n",
       "                               reg_alpha=0.005, reg_lambda=1,\n",
       "                               scale_pos_weight=1, subsample=0.7,\n",
       "                               tree_method='exact', validate_parameters=1,\n",
       "                               verbosity=None))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc 0.5482350852272727 \n",
      "\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1280\n",
      "           1       0.15      1.00      0.26       220\n",
      "\n",
      "    accuracy                           0.15      1500\n",
      "   macro avg       0.07      0.50      0.13      1500\n",
      "weighted avg       0.02      0.15      0.04      1500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_prob_val = estimator.predict_proba(X_val)[:,1]\n",
    "y_pred_val = np.where(y_prob_val > 0.13, 1, 0)\n",
    "\n",
    "print('auc',roc_auc_score(y_val,y_prob_val),'\\n')\n",
    "print('classification report \\n', classification_report(y_val,y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc 0.5622856499116298 \n",
      "\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      6956\n",
      "           1       0.15      1.00      0.26      1197\n",
      "\n",
      "    accuracy                           0.15      8153\n",
      "   macro avg       0.07      0.50      0.13      8153\n",
      "weighted avg       0.02      0.15      0.04      8153\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_prob_train = estimator.predict_proba(X_train)[:,1]\n",
    "y_pred_train = np.where(y_prob_train > 0.13, 1, 0)\n",
    "\n",
    "print('auc',roc_auc_score(y_train,y_prob_train),'\\n')\n",
    "print('classification report \\n', classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc 0.5683096590909091 \n",
      "\n",
      "classification report \n",
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1280\n",
      "           1       0.15      1.00      0.26       220\n",
      "\n",
      "    accuracy                           0.15      1500\n",
      "   macro avg       0.07      0.50      0.13      1500\n",
      "weighted avg       0.02      0.15      0.04      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prob_test = estimator.predict_proba(X_test)[:,1]\n",
    "y_pred_test = np.where(y_prob_test > 0.13, 1, 0)\n",
    "\n",
    "print('auc',roc_auc_score(y_test,y_prob_test),'\\n')\n",
    "print('classification report \\n', classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Hyperparameter Tuning (2nd Scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "    learning_rate = rates,\n",
    "    n_estimators = 100,\n",
    "    max_depth = 5,\n",
    "    min_child_weight = 6,\n",
    "    gamma= 30,\n",
    "    subsample = 0.7,\n",
    "    colsample_bynode = 0.4,\n",
    "    reg_alpha= 0.005,\n",
    "    objective= 'binary:logistic',\n",
    "    n_jobs = -1,\n",
    "    random_state = 20)\n",
    "\n",
    "# model = CalibratedClassifierCV(model)\n",
    "\n",
    "select = SelectFromModel(model, threshold=\"median\")\n",
    "\n",
    "estimator = Pipeline([\n",
    "                      ('preprocess',transformer),\n",
    "                      ('select',select),\n",
    "                      ('clf',model)\n",
    "])\n",
    "\n",
    "skfold = StratifiedKFold(n_splits = 4, shuffle = True, random_state = 200)\n",
    "\n",
    "hyperparam_space = {\n",
    "    'clf__n_estimators':[60,80,100,120,150]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator, # model to tune\n",
    "    param_grid = hyperparam_space, # hyperparameter space\n",
    "    cv = skfold, # evaluation method\n",
    "    scoring = 'roc_auc', # metrics\n",
    "    n_jobs = -1 # use all cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = grid_search.best_estimator_\n",
    "estimator.fit(X_trainval,y_trainval)\n",
    "\n",
    "y_prob_test = estimator.predict_proba(X_test)[:,1]\n",
    "y_pred_test = np.where(y_prob_test > 0.13, 1, 0)\n",
    "\n",
    "print('auc',roc_auc_score(y_test,y_prob_test),'\\n')\n",
    "print('classification report \\n', classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "    learning_rate = rates,\n",
    "    n_estimators = grid_search.best_params_['clf__n_estimators'],\n",
    "    max_depth = 5,\n",
    "    min_child_weight = 6,\n",
    "    gamma= 30,\n",
    "    subsample = 0.7,\n",
    "    colsample_bynode = 0.4,\n",
    "    reg_alpha= 0.005,\n",
    "    objective= 'binary:logistic',\n",
    "    n_jobs = -1,\n",
    "    random_state = 20)\n",
    "\n",
    "# model = CalibratedClassifierCV(model)\n",
    "\n",
    "select = SelectFromModel(model, threshold=\"median\")\n",
    "\n",
    "estimator = Pipeline([\n",
    "                      ('preprocess',transformer),\n",
    "                      ('select',select),\n",
    "                      ('clf',model)\n",
    "])\n",
    "\n",
    "# skfold = StratifiedKFold(n_splits = 4)\n",
    "\n",
    "hyperparam_space = {\n",
    "    'clf__max_depth':range(3,6),\n",
    "    'clf__min_child_weight':range(1,10)\n",
    "}\n",
    "\n",
    "grid_search2 = GridSearchCV(\n",
    "    estimator, # model to tune\n",
    "    param_grid = hyperparam_space, # hyperparameter space\n",
    "    cv = skfold, # evaluation method\n",
    "    scoring = 'roc_auc', # metrics\n",
    "    n_jobs = -1 # use all cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search2.fit(X_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search2.best_params_)\n",
    "print(grid_search2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = grid_search2.best_estimator_\n",
    "estimator.fit(X_trainval,y_trainval)\n",
    "\n",
    "y_prob_test = estimator.predict_proba(X_test)[:,1]\n",
    "y_pred_test = np.where(y_prob_test > 0.13, 1, 0)\n",
    "\n",
    "print('auc',roc_auc_score(y_test,y_prob_test),'\\n')\n",
    "print('classification report \\n', classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "    learning_rate = rates,\n",
    "    n_estimators = grid_search.best_params_['clf__n_estimators'],\n",
    "    max_depth = grid_search2.best_params_['clf__max_depth'],\n",
    "    min_child_weight = grid_search2.best_params_['clf__min_child_weight'],\n",
    "    gamma= 30,\n",
    "    subsample = 0.7,\n",
    "    colsample_bynode = 0.4,\n",
    "    reg_alpha= 0.005,\n",
    "    objective= 'binary:logistic',\n",
    "    n_jobs = -1,\n",
    "    random_state = 20)\n",
    "\n",
    "# model = CalibratedClassifierCV(model)\n",
    "\n",
    "select = SelectFromModel(model, threshold=\"median\")\n",
    "\n",
    "estimator = Pipeline([\n",
    "                      ('preprocess',transformer),\n",
    "                      ('select',select),\n",
    "                      ('clf',model)\n",
    "])\n",
    "\n",
    "# skfold = StratifiedKFold(n_splits = 4)\n",
    "\n",
    "hyperparam_space = {\n",
    "    'clf__gamma':[25,30,35,40],\n",
    "    'clf__colsample_bynode':[i/10 for i in range(2,6)]\n",
    "}\n",
    "\n",
    "grid_search3 = GridSearchCV(\n",
    "    estimator, # model to tune\n",
    "    param_grid = hyperparam_space, # hyperparameter space\n",
    "    cv = skfold, # evaluation method\n",
    "    scoring = 'roc_auc', # metrics\n",
    "    n_jobs = -1 # use all cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search3.fit(X_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search3.best_params_)\n",
    "print(grid_search3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = grid_search3.best_estimator_\n",
    "estimator.fit(X_trainval,y_trainval)\n",
    "\n",
    "y_prob_test = estimator.predict_proba(X_test)[:,1]\n",
    "y_pred_test = np.where(y_prob_test > 0.13, 1, 0)\n",
    "\n",
    "print('auc',roc_auc_score(y_test,y_prob_test),'\\n')\n",
    "print('classification report \\n', classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "    learning_rate = rates,\n",
    "    n_estimators = grid_search.best_params_['clf__n_estimators'],\n",
    "    max_depth = grid_search2.best_params_['clf__max_depth'],\n",
    "    min_child_weight = grid_search2.best_params_['clf__min_child_weight'],\n",
    "    gamma= grid_search3.best_params_['clf__gamma'],\n",
    "    subsample = 0.7,\n",
    "    colsample_bynode = grid_search3.best_params_['clf__colsample_bynode'],\n",
    "    reg_alpha= 0.005,\n",
    "    objective= 'binary:logistic',\n",
    "    n_jobs = -1,\n",
    "    random_state = 20)\n",
    "\n",
    "# model = CalibratedClassifierCV(model)\n",
    "\n",
    "select = SelectFromModel(model, threshold=\"median\")\n",
    "\n",
    "estimator = Pipeline([\n",
    "                      ('preprocess',transformer),\n",
    "                      ('select',select),\n",
    "                      ('clf',model)\n",
    "])\n",
    "\n",
    "# skfold = StratifiedKFold(n_splits = 4)\n",
    "\n",
    "hyperparam_space = {\n",
    "    'clf__subsample':[i/10.0 for i in range(6,8)]\n",
    "}\n",
    "\n",
    "grid_search4 = GridSearchCV(\n",
    "    estimator, # model to tune\n",
    "    param_grid = hyperparam_space, # hyperparameter space\n",
    "    cv = skfold, # evaluation method\n",
    "    scoring = 'roc_auc', # metrics\n",
    "    n_jobs = -1 # use all cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search4.fit(X_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search4.best_params_)\n",
    "print(grid_search4.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = grid_search4.best_estimator_\n",
    "estimator.fit(X_trainval,y_trainval)\n",
    "\n",
    "y_prob_test = estimator.predict_proba(X_test)[:,1]\n",
    "y_pred_test = np.where(y_prob_test > 0.13, 1, 0)\n",
    "\n",
    "print('auc',roc_auc_score(y_test,y_prob_test),'\\n')\n",
    "print('classification report \\n', classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "    learning_rate = rates,\n",
    "    n_estimators = grid_search.best_params_['clf__n_estimators'],\n",
    "    max_depth = grid_search2.best_params_['clf__max_depth'],\n",
    "    min_child_weight = grid_search2.best_params_['clf__min_child_weight'],\n",
    "    gamma= grid_search3.best_params_['clf__gamma'],\n",
    "    subsample = grid_search4.best_params_['clf__subsample'],\n",
    "    colsample_bynode = grid_search3.best_params_['clf__colsample_bynode'],\n",
    "    reg_alpha= 0.005,\n",
    "    objective= 'binary:logistic',\n",
    "    n_jobs = -1,\n",
    "    random_state = 20)\n",
    "\n",
    "# model = CalibratedClassifierCV(model)\n",
    "\n",
    "select = SelectFromModel(model, threshold=\"median\")\n",
    "\n",
    "estimator = Pipeline([\n",
    "                      ('preprocess',transformer),\n",
    "                      ('select',select),\n",
    "                      ('clf',model)\n",
    "])\n",
    "\n",
    "# skfold = StratifiedKFold(n_splits = 4)\n",
    "\n",
    "hyperparam_space = {\n",
    "    'clf__reg_alpha':[0.0005, 0.005, 0.001, 0.05, 0.01, 0.5, 0.1, 10],\n",
    "    'clf__reg_lambda':[None, 0.001, 0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "grid_search5 = GridSearchCV(\n",
    "    estimator, # model to tune\n",
    "    param_grid = hyperparam_space, # hyperparameter space\n",
    "    cv = skfold, # evaluation method\n",
    "    scoring = 'roc_auc', # metrics\n",
    "    n_jobs = -1 # use all cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search5.fit(X_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search5.best_params_)\n",
    "print(grid_search5.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = grid_search5.best_estimator_\n",
    "estimator.fit(X_trainval,y_trainval)\n",
    "\n",
    "y_prob_test = estimator.predict_proba(X_test)[:,1]\n",
    "y_pred_test = np.where(y_prob_test > 0.13, 1, 0)\n",
    "\n",
    "print('auc',roc_auc_score(y_test,y_prob_test),'\\n')\n",
    "print('classification report \\n', classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "    learning_rate = rates,\n",
    "    n_estimators = grid_search.best_params_['clf__n_estimators'],\n",
    "    max_depth = grid_search2.best_params_['clf__max_depth'],\n",
    "    min_child_weight = grid_search2.best_params_['clf__min_child_weight'],\n",
    "    gamma= grid_search3.best_params_['clf__gamma'],\n",
    "    subsample = grid_search4.best_params_['clf__subsample'],\n",
    "    colsample_bynode = grid_search3.best_params_['clf__colsample_bynode'],\n",
    "    reg_alpha = grid_search5.best_params_['clf__reg_alpha'],\n",
    "    reg_lambda = grid_search5.best_params_['clf__reg_lambda'],\n",
    "    objective = 'binary:logistic',\n",
    "    n_jobs = -1)\n",
    "\n",
    "# model = CalibratedClassifierCV(model)\n",
    "\n",
    "select = SelectFromModel(model, threshold=\"median\")\n",
    "\n",
    "estimator = Pipeline([\n",
    "                      ('preprocess',transformer),\n",
    "                      ('select',select),\n",
    "                      ('clf',model)\n",
    "])\n",
    "\n",
    "# skfold = StratifiedKFold(n_splits = 4)\n",
    "\n",
    "hyperparam_space = [\n",
    "    {'clf__learning_rate':[rates],'clf__n_estimators':[grid_search.best_params_['clf__n_estimators']]},\n",
    "    {'clf__learning_rate':[rates/2],'clf__n_estimators':[grid_search.best_params_['clf__n_estimators']*2]}#,\n",
    "#     {'clf__learning_rate':[rates/4],'clf__n_estimators':[grid_search.best_params_['clf__n_estimators']*4]},\n",
    "#     {'clf__learning_rate':[rates/8],'clf__n_estimators':[grid_search.best_params_['clf__n_estimators']*8]},\n",
    "#     {'clf__learning_rate':[rates/16],'clf__n_estimators':[grid_search.best_params_['clf__n_estimators']*16]}\n",
    "]\n",
    "\n",
    "grid_search6 = GridSearchCV(\n",
    "    estimator, # model to tune\n",
    "    param_grid = hyperparam_space, # hyperparameter space\n",
    "    cv = skfold, # evaluation method\n",
    "    scoring = 'roc_auc', # metrics\n",
    "    n_jobs = -1 # use all cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search6.fit(X_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search6.best_params_)\n",
    "print(grid_search6.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = grid_search6.best_estimator_\n",
    "estimator.fit(X_trainval,y_trainval)\n",
    "\n",
    "y_prob_test = estimator.predict_proba(X_test)[:,1]\n",
    "y_pred_test = np.where(y_prob_test > 0.13, 1, 0)\n",
    "\n",
    "print('auc',roc_auc_score(y_test,y_prob_test),'\\n')\n",
    "print('classification report \\n', classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "    learning_rate = grid_search6.best_params_['clf__learning_rate'],\n",
    "    n_estimators = grid_search6.best_params_['clf__n_estimators'],\n",
    "    max_depth = grid_search2.best_params_['clf__max_depth'],\n",
    "    min_child_weight = grid_search2.best_params_['clf__min_child_weight'],\n",
    "    gamma= grid_search3.best_params_['clf__gamma'],\n",
    "    subsample = grid_search4.best_params_['clf__subsample'],\n",
    "    colsample_bynode = grid_search3.best_params_['clf__colsample_bynode'],\n",
    "    reg_alpha = grid_search5.best_params_['clf__reg_alpha'],\n",
    "    reg_lambda = grid_search5.best_params_['clf__reg_lambda'],\n",
    "    objective = 'binary:logistic',\n",
    "    n_jobs = -1)\n",
    "\n",
    "select = SelectFromModel(model, threshold=\"median\")\n",
    "\n",
    "model = CalibratedClassifierCV(model)\n",
    "\n",
    "final_estimator = Pipeline([\n",
    "                      ('preprocess',transformer),\n",
    "                      ('select',select),\n",
    "                      ('clf',model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_estimator.fit(X_trainval,y_trainval)\n",
    "\n",
    "y_prob_test = final_estimator.predict_proba(X_test)[:,1]\n",
    "y_pred_test = np.where(y_prob_test > 0.13, 1, 0)\n",
    "\n",
    "print('auc',roc_auc_score(y_test,y_prob_test),'\\n')\n",
    "print('classification report \\n', classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_trainval = final_estimator.predict_proba(X_trainval)[:,1]\n",
    "y_pred_trainval = np.where(y_prob_trainval > 0.13, 1, 0)\n",
    "\n",
    "print('auc',roc_auc_score(y_trainval,y_prob_trainval),'\\n')\n",
    "print('classification report \\n', classification_report(y_trainval,y_pred_trainval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "    learning_rate = grid_search6.best_params_['clf__learning_rate'],\n",
    "    n_estimators = grid_search6.best_params_['clf__n_estimators'],\n",
    "    max_depth = grid_search2.best_params_['clf__max_depth'],\n",
    "    min_child_weight = grid_search2.best_params_['clf__min_child_weight'],\n",
    "    gamma= grid_search3.best_params_['clf__gamma'],\n",
    "    subsample = grid_search4.best_params_['clf__subsample'],\n",
    "    colsample_bynode = grid_search3.best_params_['clf__colsample_bynode'],\n",
    "    reg_alpha = grid_search5.best_params_['clf__reg_alpha'],\n",
    "    reg_lambda = grid_search5.best_params_['clf__reg_lambda'],\n",
    "    objective = 'binary:logistic',\n",
    "    n_jobs = -1)\n",
    "\n",
    "select = SelectFromModel(model, threshold=\"median\")\n",
    "\n",
    "model = CalibratedClassifierCV(model)\n",
    "\n",
    "final_estimator = Pipeline([\n",
    "                      ('preprocess',transformer),\n",
    "                      ('select',select),\n",
    "                      ('clf',model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_estimator = grid_search2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_estimator.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sub = final_estimator.predict_proba(X_sub)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Best Performance'] = y_pred_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = df_test[['Best Performance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.reset_index().to_csv('submission v1 - step by step.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
