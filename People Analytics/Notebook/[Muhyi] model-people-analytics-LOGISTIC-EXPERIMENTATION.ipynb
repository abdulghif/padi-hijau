{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\distributed\\config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "\n",
    "# library untuk eksplorasi data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# library untuk membagi data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# library untuk evaluasi hasil prediksi\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# library untuk bebrapa model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# library untuk tunning parameter\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# library untuk menggabungkan beberapa algoritme\n",
    "from imblearn.pipeline import Pipeline\n",
    "# library untuk menyeimbangkan data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# import category_encoders as ce\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_prep.csv')\n",
    "df_test = pd.read_csv('test_prep.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepaparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_prep1 = df_train.copy()\n",
    "df_test_prep1 = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_var_one_hot = ['age2','age3','year_graduated2','in study','person level up','sick_vs_leaves']\n",
    "\n",
    "one_hot_var = [\n",
    "    'job_level_oh', \n",
    "    'person_level_oh', \n",
    "    'Employee_type', \n",
    "    'Education_level',\n",
    "#     'Employee_status',   \n",
    "    'gender', \n",
    "    'marital_status_maried(Y/N)'] + new_var_one_hot\n",
    "\n",
    "ordinal_val = [\n",
    "    'job_level',\n",
    "    'person_level',\n",
    "    'Education_level'\n",
    "#     'achievement_target_1', \n",
    "#     'achievement_target_2'\n",
    "]\n",
    "\n",
    "new_var_num = ['year_graduated','total leave','total_rotation',\n",
    "               'age when graduated','age when graduated2','papa muda',\n",
    "               'papa muda per tanggungan','age per dependencies']\n",
    "\n",
    "numeric_var = [\n",
    "    'job_duration_in_current_job_level',   \n",
    "    'job_duration_in_current_person_level',\n",
    "    'job_duration_in_current_branch', \n",
    "    'age', \n",
    "    'number_of_dependences',\n",
    "    'GPA',   \n",
    "    'branch_rotation', \n",
    "    'job_rotation', \n",
    "    'assign_of_otherposition',   \n",
    "    'annual leave', \n",
    "    'sick_leaves',\n",
    "    'Last_achievement_%', \n",
    "    'Achievement_above_100%_during3quartal'] + new_var_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal_mapping = [\n",
    "#     {'col':'job_level',\n",
    "#     'mapping':{None:0,'JG04':1,'JG05':2,'JG03':3,'JG06':4}},\n",
    "#     {'col':'person_level',\n",
    "#     'mapping':{None:0,'PG01':1,'PG02':2,'PG03':3,'PG04':4, 'PG05':5, 'PG06':6, 'PG07':7, 'PG08':8}},\n",
    "#     {'col':'Education_level',\n",
    "#     'mapping':{None:0,'level_0':1,'level_1':2,'level_2':3, 'level_3':4, 'level_4':5, 'level_5':6}}    \n",
    "#     ]\n",
    "\n",
    "# ordinal_encoder = ce.OrdinalEncoder(cols = ['job_level','person_level','Education_level'],mapping = ordinal_mapping)\n",
    "\n",
    "one_hot_encoder_pipeline = Pipeline([\n",
    "                                    ('one hot encoder',OneHotEncoder(handle_unknown = 'ignore'))\n",
    "])\n",
    "\n",
    "# numerical_pipeline = SimpleImputer(strategy = 'constant',fill_value = 0)\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "                                ('imputer',SimpleImputer(strategy = 'constant',fill_value = 0)),\n",
    "                                ('bin',KBinsDiscretizer(encode = 'onehot',strategy = 'kmeans',n_bins=5))\n",
    "])\n",
    "\n",
    "transformer = ColumnTransformer([\n",
    "    ('one hot encoder',one_hot_encoder_pipeline,one_hot_var),\n",
    "#     ('ordinal encoder',ordinal_encoder,ordinal_val),\n",
    "    ('numerical_pipeline',numerical_pipeline,numeric_var)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_x = numeric_var + one_hot_var #+ ordinal_val\n",
    "\n",
    "X = df_train_prep1[var_x]\n",
    "X_sub = df_test_prep1[var_x]\n",
    "y = df_train_prep1['Best Performance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 1995\n",
    "seed = 70621\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X,y, stratify = y, test_size = 1500, random_state = seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval,y_trainval, stratify = y_trainval, test_size = 1500, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Model (Benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver = 'newton-cg')\n",
    "\n",
    "estimator = Pipeline([\n",
    "                      ('preprocess',transformer),\n",
    "                      ('clf',model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:189: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n",
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:202: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 12 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocess',\n",
       "                 ColumnTransformer(transformers=[('one hot encoder',\n",
       "                                                  Pipeline(steps=[('one hot '\n",
       "                                                                   'encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['job_level_oh',\n",
       "                                                   'person_level_oh',\n",
       "                                                   'Employee_type',\n",
       "                                                   'Education_level', 'gender',\n",
       "                                                   'marital_status_maried(Y/N)',\n",
       "                                                   'age2', 'age3',\n",
       "                                                   'year_graduated2',\n",
       "                                                   'in study',\n",
       "                                                   'person level up',\n",
       "                                                   'sick_vs_leaves']),\n",
       "                                                 ('numerical...\n",
       "                                                   'number_of_dependences',\n",
       "                                                   'GPA', 'branch_rotation',\n",
       "                                                   'job_rotation',\n",
       "                                                   'assign_of_otherposition',\n",
       "                                                   'annual leave',\n",
       "                                                   'sick_leaves',\n",
       "                                                   'Last_achievement_%',\n",
       "                                                   'Achievement_above_100%_during3quartal',\n",
       "                                                   'year_graduated',\n",
       "                                                   'total leave',\n",
       "                                                   'total_rotation',\n",
       "                                                   'age when graduated',\n",
       "                                                   'age when graduated2',\n",
       "                                                   'papa muda',\n",
       "                                                   'papa muda per tanggungan',\n",
       "                                                   'age per dependencies'])])),\n",
       "                ('clf', LogisticRegression(solver='newton-cg'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc 0.5545703125 \n",
      "\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.45      0.59      1280\n",
      "           1       0.17      0.64      0.26       220\n",
      "\n",
      "    accuracy                           0.47      1500\n",
      "   macro avg       0.52      0.54      0.43      1500\n",
      "weighted avg       0.77      0.47      0.54      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prob_val = estimator.predict_proba(X_val)[:,1]\n",
    "y_pred_val = np.where(y_prob_val > 0.13, 1, 0)\n",
    "\n",
    "print('auc',roc_auc_score(y_val,y_prob_val),'\\n')\n",
    "print('classification report \\n', classification_report(y_val,y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc 0.6209941544488017 \n",
      "\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.47      0.62      6956\n",
      "           1       0.18      0.70      0.29      1197\n",
      "\n",
      "    accuracy                           0.50      8153\n",
      "   macro avg       0.54      0.58      0.45      8153\n",
      "weighted avg       0.80      0.50      0.57      8153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prob_train = estimator.predict_proba(X_train)[:,1]\n",
    "y_pred_train = np.where(y_prob_train > 0.13, 1, 0)\n",
    "\n",
    "print('auc',roc_auc_score(y_train,y_prob_train),'\\n')\n",
    "print('classification report \\n', classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc 0.5917933238636364 \n",
      "\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.46      0.61      1280\n",
      "           1       0.18      0.70      0.29       220\n",
      "\n",
      "    accuracy                           0.49      1500\n",
      "   macro avg       0.54      0.58      0.45      1500\n",
      "weighted avg       0.79      0.49      0.56      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prob_test = estimator.predict_proba(X_test)[:,1]\n",
    "y_pred_test = np.where(y_prob_test > 0.13, 1, 0)\n",
    "\n",
    "print('auc',roc_auc_score(y_test,y_prob_test),'\\n')\n",
    "print('classification report \\n', classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = XGBClassifier(\n",
    "    learning_rate = 0.05,\n",
    "    n_estimators = 1000,\n",
    "    max_depth = 5,\n",
    "    min_child_weight = 4,\n",
    "    gamma= 30,\n",
    "    subsample = 0.7,\n",
    "    colsample_bynode = 0.4,\n",
    "    reg_alpha= 0.005,\n",
    "    objective= 'binary:logistic',\n",
    "    n_jobs = -1,\n",
    "    seed=27)\n",
    "\n",
    "# model_xgb = CalibratedClassifierCV(model)\n",
    "\n",
    "model_logreg = LogisticRegression(solver = 'newton-cg')\n",
    "model_knn = KNeighborsClassifier()\n",
    "model_dtc = DecisionTreeClassifier()\n",
    "model_rf = RandomForestClassifier()\n",
    "# model_svc = SVC(kernel = 'rbf')\n",
    "\n",
    "estimator = Pipeline([\n",
    "                      ('preprocess',transformer),\n",
    "                      ('clf',model)\n",
    "])\n",
    "\n",
    "skfold = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "hyperparam_space = {\n",
    "    'clf':[model_xgb, model_logreg, model_knn, model_dtc, model_rf]\n",
    "}\n",
    "\n",
    "grid_search_model = GridSearchCV(\n",
    "    estimator, # model to tune\n",
    "    param_grid = hyperparam_space, # hyperparameter space\n",
    "    cv = skfold, # evaluation method\n",
    "    scoring = 'roc_auc', # metrics\n",
    "    n_jobs = -1 # use all cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:189: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n",
      "C:\\Users\\muhyi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:202: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 12 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('preprocess',\n",
       "                                        ColumnTransformer(transformers=[('one '\n",
       "                                                                         'hot '\n",
       "                                                                         'encoder',\n",
       "                                                                         Pipeline(steps=[('one '\n",
       "                                                                                          'hot '\n",
       "                                                                                          'encoder',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                         ['job_level_oh',\n",
       "                                                                          'person_level_oh',\n",
       "                                                                          'Employee_type',\n",
       "                                                                          'Education_level',\n",
       "                                                                          'gender',\n",
       "                                                                          'marital_status_maried(Y/...\n",
       "                                               monotone_constraints=None,\n",
       "                                               n_estimators=1000, n_jobs=-1,\n",
       "                                               num_parallel_tree=None,\n",
       "                                               random_state=None,\n",
       "                                               reg_alpha=0.005, reg_lambda=None,\n",
       "                                               scale_pos_weight=None, seed=27,\n",
       "                                               subsample=0.7, tree_method=None,\n",
       "                                               validate_parameters=None,\n",
       "                                               verbosity=None),\n",
       "                                 LogisticRegression(solver='newton-cg'),\n",
       "                                 KNeighborsClassifier(),\n",
       "                                 DecisionTreeClassifier(),\n",
       "                                 RandomForestClassifier()]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_model.fit(X_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf': LogisticRegression(solver='newton-cg')}\n",
      "0.5627476379565657\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_model.best_params_)\n",
    "print(grid_search_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.782209</td>\n",
       "      <td>0.071982</td>\n",
       "      <td>0.040093</td>\n",
       "      <td>0.003646</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'clf': XGBClassifier(base_score=None, booster...</td>\n",
       "      <td>0.539521</td>\n",
       "      <td>0.556744</td>\n",
       "      <td>0.566059</td>\n",
       "      <td>0.553818</td>\n",
       "      <td>0.545408</td>\n",
       "      <td>0.552310</td>\n",
       "      <td>0.009189</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.069987</td>\n",
       "      <td>0.117769</td>\n",
       "      <td>0.032114</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>LogisticRegression(solver='newton-cg')</td>\n",
       "      <td>{'clf': LogisticRegression(solver='newton-cg')}</td>\n",
       "      <td>0.551582</td>\n",
       "      <td>0.548659</td>\n",
       "      <td>0.575032</td>\n",
       "      <td>0.571703</td>\n",
       "      <td>0.566762</td>\n",
       "      <td>0.562748</td>\n",
       "      <td>0.010681</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.819408</td>\n",
       "      <td>0.185713</td>\n",
       "      <td>2.683422</td>\n",
       "      <td>0.176673</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>{'clf': KNeighborsClassifier()}</td>\n",
       "      <td>0.499464</td>\n",
       "      <td>0.490876</td>\n",
       "      <td>0.527054</td>\n",
       "      <td>0.524145</td>\n",
       "      <td>0.512513</td>\n",
       "      <td>0.510811</td>\n",
       "      <td>0.013933</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.799987</td>\n",
       "      <td>0.150465</td>\n",
       "      <td>0.046675</td>\n",
       "      <td>0.010543</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>{'clf': DecisionTreeClassifier()}</td>\n",
       "      <td>0.511114</td>\n",
       "      <td>0.517631</td>\n",
       "      <td>0.529170</td>\n",
       "      <td>0.495092</td>\n",
       "      <td>0.508050</td>\n",
       "      <td>0.512211</td>\n",
       "      <td>0.011212</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.827462</td>\n",
       "      <td>0.325266</td>\n",
       "      <td>0.065226</td>\n",
       "      <td>0.010337</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>{'clf': RandomForestClassifier()}</td>\n",
       "      <td>0.533023</td>\n",
       "      <td>0.519622</td>\n",
       "      <td>0.565898</td>\n",
       "      <td>0.532743</td>\n",
       "      <td>0.539550</td>\n",
       "      <td>0.538167</td>\n",
       "      <td>0.015302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      12.782209      0.071982         0.040093        0.003646   \n",
       "1       3.069987      0.117769         0.032114        0.002554   \n",
       "2       0.819408      0.185713         2.683422        0.176673   \n",
       "3       1.799987      0.150465         0.046675        0.010543   \n",
       "4       7.827462      0.325266         0.065226        0.010337   \n",
       "\n",
       "                                           param_clf  \\\n",
       "0  XGBClassifier(base_score=None, booster=None, c...   \n",
       "1             LogisticRegression(solver='newton-cg')   \n",
       "2                             KNeighborsClassifier()   \n",
       "3                           DecisionTreeClassifier()   \n",
       "4                           RandomForestClassifier()   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'clf': XGBClassifier(base_score=None, booster...           0.539521   \n",
       "1    {'clf': LogisticRegression(solver='newton-cg')}           0.551582   \n",
       "2                    {'clf': KNeighborsClassifier()}           0.499464   \n",
       "3                  {'clf': DecisionTreeClassifier()}           0.511114   \n",
       "4                  {'clf': RandomForestClassifier()}           0.533023   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.556744           0.566059           0.553818           0.545408   \n",
       "1           0.548659           0.575032           0.571703           0.566762   \n",
       "2           0.490876           0.527054           0.524145           0.512513   \n",
       "3           0.517631           0.529170           0.495092           0.508050   \n",
       "4           0.519622           0.565898           0.532743           0.539550   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.552310        0.009189                2  \n",
       "1         0.562748        0.010681                1  \n",
       "2         0.510811        0.013933                5  \n",
       "3         0.512211        0.011212                4  \n",
       "4         0.538167        0.015302                3  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search_model.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Hyperparameter Tuning Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoder_pipeline = Pipeline([\n",
    "                                    ('one hot encoder',OneHotEncoder(handle_unknown = 'ignore'))\n",
    "])\n",
    "\n",
    "# numerical_pipeline = SimpleImputer(strategy = 'constant',fill_value = 0)\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "                                ('imputer',SimpleImputer(strategy = 'constant',fill_value = 0)),\n",
    "                                ('bin',KBinsDiscretizer(encode = 'onehot',strategy = 'uniform'))\n",
    "])\n",
    "\n",
    "transformer = ColumnTransformer([\n",
    "    ('one hot encoder',one_hot_encoder_pipeline,one_hot_var),\n",
    "#     ('ordinal encoder',ordinal_encoder,ordinal_val),\n",
    "    ('numerical_pipeline',numerical_pipeline,numeric_var)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver = 'newton-cg')\n",
    "\n",
    "select = SelectFromModel(model, threshold=\"median\")\n",
    "\n",
    "estimator = Pipeline([\n",
    "                      ('preprocess',transformer),\n",
    "                      ('select',select),\n",
    "                      ('clf',model)\n",
    "])\n",
    "\n",
    "skfold = StratifiedKFold(n_splits = 4)\n",
    "\n",
    "hyperparam_space = [{\n",
    "    'preprocess__numerical_pipeline__bin__n_bins':[3,4,5,6],\n",
    "    'preprocess__numerical_pipeline__bin__encode':['ordinal','onehot'],\n",
    "    'preprocess__numerical_pipeline__bin__strategy':['uniform','quantile','kmeans'],\n",
    "    'select__threshold':['0.5*median','0.75*median','median','1.25*median','1.5*median'],\n",
    "    'clf__C':[0.001,0.01,0.1,1,10,100,1000]},\n",
    "    {'preprocess__numerical_pipeline__bin__n_bins':[3,4,5,6],\n",
    "    'preprocess__numerical_pipeline__bin__encode':['ordinal','onehot'],\n",
    "    'preprocess__numerical_pipeline__bin__strategy':['uniform','quantile','kmeans'],\n",
    "    'select':[None],\n",
    "    'clf__C':[0.001,0.01,0.1,1,10,100,1000]}\n",
    "]\n",
    "\n",
    "grid_search_simple = GridSearchCV(\n",
    "    estimator, # model to tune\n",
    "    param_grid = hyperparam_space, # hyperparameter space\n",
    "    cv = skfold, # evaluation method\n",
    "    scoring = 'roc_auc', # metrics\n",
    "    n_jobs = -1 # use all cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_simple.fit(X_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_simple.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_simple.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = grid_search_simple.best_estimator_\n",
    "estimator.fit(X_trainval,y_trainval)\n",
    "\n",
    "y_prob_test = estimator.predict_proba(X_test)[:,1]\n",
    "y_pred_test = np.where(y_prob_test > 0.13, 1, 0)\n",
    "\n",
    "print('auc',roc_auc_score(y_test,y_prob_test),'\\n')\n",
    "print('classification report \\n', classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_trainval = estimator.predict_proba(X_trainval)[:,1]\n",
    "y_pred_trainval = np.where(y_prob_trainval > 0.13, 1, 0)\n",
    "\n",
    "print('auc',roc_auc_score(y_trainval,y_prob_trainval),'\\n')\n",
    "print('classification report \\n', classification_report(y_trainval,y_pred_trainval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator = grid_search_simple.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sub = estimator.predict_proba(X_sub)[:,1]\n",
    "df_test['Best Performance'] = y_pred_sub\n",
    "df_submission = df_test[['Best Performance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.reset_index().to_csv('submission logreg2.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
